# Node.js

Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient. Node.js package ecosystem, npm is the largest ecosystem of open source libraries in the world.

Node.js allows us to run a JavaScript code outside of the browser – on the server side. To write application’s backends, web-servers, command line interfaces.

What can we do with Node.js? Using Node.js we can:

- Run JavaScript outside the browser
- Work with files
- Create web servers
- Interact with databases
- Write reusable "packages"

## Node Version Manager

The best way to manage multiple versions of Node.js is to use **Node Version Manager (NVM)**.

## Package.json

Package.json helps us to do two things:

- Create a package for our project by running - `npm init`
- Track and install additional external project dependencies

We can create script shortcuts in the package.json file. To run the script we can call with `npm run <script name>`
In order to run node scripts with arguments we can just pass any argument number after the node keyword and the script name, then inside our code we can access them via the **process** object - `process.argv.slice(2)`. We exclude the first two elements of the arguments array, because they are the paths of the node executable file and the file we are executing.

## Importing npm Modules

We can import external packages by either installing a specific package or by defining what other dependencies our package use in a package.json file.

    • Run npm install (npm i) or
    • Run npm I <package>

What this does is the following:

1. It will go to the npm registry (npm servers)
2. Grab all of the code for that specific package
3. Add it to our project
4. It will create package-lock.json file
5. It will create a node_modules directory

The package-lock.json holds a link pointing to exactly from where the package was fetched and a `sha-<hash>` information to ensure that the exact code is downloaded.

There are two ways to work with Node.js modules:

- Old way:

  - `module.exports = something`
  - `const something = require('something')`

- Modern way:
  - Add the key/pair `"type": "module"` in package.json
  - `import/export`

## Avoiding Global Modules

It is wise to avoid using global modules in node. Taking the nodemon for example, this means that when we ship the application (package) it will result in an error when somebody tries to run the package. That is why we should always prefer using locally installed (available) dependencies.

## Node REPL

Repl module provides a Read-Eval-Print-Loop (REPL) implementation that is available both as a standalone program or includible in other applications.

Node repl can also be accessed by calling “node” in a regular terminal and write JavaScript similar to writing JavaScript in browser console.

- Window is a global object in the browser
- Global is a global object in the nodejs

## Getting Users Input

In node.js we can get inputs from users or pass arguments through via command interface accessed via process.argv property. This is useful when using npm scripts, or pass external arguments to a node script.

A much better alternative is to use a module called yargs.

```js
const yargs = require('yargs');

// // Using command arguments accessed via process.arg, skipping the first two elements (paths to node bin & file that is being executed)
// const name = process.argv.slice(2);
// console.log(`Hello ${name}`);

// Using yargs module
// Customize yargs version
yargs.version('1.1.0');

// Create add command
yargs.command({
    command: 'add',
    describe: 'Add a new note',
    builder: {
        title: {
            describe: 'Note title',
            demandOption: true,
            type: 'string',
        },
        body: {
            describe: 'Note body',
            demandOption: true,
            type: 'string',
        },
    },
    handler: function (argv) {
        // make sure to use the arguments here
        console.log('Title: ', argv);
        console.log('Body: ' + argv.body);
    },
});

// Create list command
yargs.command({
    command: 'list',
    describe: 'List your notes',
    handler: function () {
        console.log('Listing out all note');
    },
});

// Create read command
yargs.command({
    command: 'read',
    describe: 'Read your notes',
    handler: function () {
        console.log('Reading a note');
    },
});

// yargs will not work if we do not call the yargs.argv or use yargs.parse();
// console.log(yargs.argv);
yargs.parse();
```

## Call Stack, Callback Queue & Event Loop

JavaScript is a single threaded programming language, you can do one thing at a time, and the Call Stack enforces that. We can have only one function on top of the Call Stack, there is no way to execute two things at the same time. Now this does not mean that Node.js is completely single-threaded, node uses other threads written in C++ behind the scene to manage events, that is what allows us to continue running up our application while we are waiting – this is the non-blocking nature of node.js.

1. Function calls are added to the Call Stack
2. Once the function is finished it gets removed from the Call Stack

The job of a Callback Queue is simple – its job is to maintain a list of all the callback functions that are ready to be executed. So when a given event is done that callback function is gonna get added to the Callback Queue, which is a standard line (FIFO).

A callback function is then added to the Call Stack if the Call stack is empty.

## Babel

Babel is a JavaScript compiler. A code transpiler that programmers use to transform a JavaScript code written in one version to run on older environments. It allows us to write modern JavaScript code which gets transformed into older JavaScript code.

1. Use `export/import`
2. Use `@babel/presets-env` inside of a `.babelrc` file
3. Use `babel-node` to start or execute a script

Note: The above uses babel-node, which is transpiles the code in memory, so it could become really slow. The alternative is to use babel and transpile code prior to execution. This means create a transpiled binaries in a give output directory and execute that code.

`npx babel src --out-dir build -config-file ./.babelrc`

The above command will create a build folder with all the code transpiled.

We can also define more babel plugins inside the `.babelrc` file, under the property called plugins and set it as an array of elements (plugins).

## Read & Write Files

The Node.js runtime allows us to use JavaScript to read and write files, which was previously not possible.

1. Understand the fs package
2. Read & Write files **synchronously**
3. Read & Write files **asynchronously**
4. Read & Write files **asynchronously** with **Callbacks**
5. Read & Write files **asynchronously** with **Promises**

```js
import fs from 'fs';
import path from 'path';

const fsPromise = fs.promises;

// Process files synchronously
fs.readFileSync(path.join(__dirname, 'fibonacci.js'), 'utf-8');
fs.writeFileSync(path.join(__dirname, 'new-file.txt'), 'Hello World! This is a new file', 'utf-8');
fs.writeFileSync(path.join(__dirname, 'new-file.txt'), 'Hello World! This is a new file', 'utf-8'); // if file exists it will override it
fs.appendFileSync(path.join(__dirname, 'new-file.txt'), '\n :D', 'utf-8');
fs.unlinkSync(path.join(__dirname, 'new-file.txt'));
fs.mkdirSync(path.join(__dirname, 'parentDirectory', 'childDirectory'), { recursive: true });
fs.rmdirSync(path.join(__dirname, 'parentDirectory', 'childDirectory'), { recursive: true });
fs.existsSync(path.join(__dirname, 'new-file.txt'));

// Process files asynchronously using callbacks
fs.readFile(path.join(__dirname, 'fibonacci.js'), 'utf-8', (err, res) => {
    if (err) console.log(err);
    console.log(res);
});

fs.writeFile(path.join(__dirname, 'fibonacci.js'), 'utf-8', (err, res) => {
    if (err) console.log(err);
    console.log(res);
});

fs.writeFile(path.join(__dirname, 'test.js'), 'utf-8', (err, res) => {
    fs.readFile(path.join(__dirname, 'fibonacci.js'), 'utf-8', (err, res) => {
        if (err) console.log(err);
        return res;
    });
});

// Process files asynchronously using async/await
async function printAsyncResult() {
    const result = await fsPromise.readFile(path.join(__dirname, 'fibonacci.js'), 'utf-8');
    console.log(result);
}

printAsyncResult();
```

## Web Servers

There are several ways of creating web-servers in Node.js:

1. Create a web server **without** frameworks (built-in **http**/**https** modules)
2. Use **express.js** to create a web server
3. Use **Koa.js** to create a web server
4. Use **Hapi** to create a web server

- Serving up HTML and JSON
- Serving up Static Assets
- Serving up CSS JS Images

```js
// No framework
import http from 'http';

const server = http.createServer((req, res) => {
    const { url } = req;
    res.write('Hello');
    res.end();
});

server.listen(3333, () => {
    console.log('server started listening on port 3333');
});

// Express.js
import express from 'express';

const app = express();

app.use(express.json());

app.get('/hello', (req, res, next) => {
    res.send({ message: 'received a GET request' });
});

app.listen(1337, () => {
    console.log('Express server is listening on port 1337');
});

// Koa.js
import Koa from 'koa';

const app = new Koa();

app.use(async (ctx, next) => {
    ctx.type = 'application/json';

    // can be called multiple times, it adds something to the context and passes it to the next callback
    await next();
});

app.use(async (ctx, next) => {
    ctx.body = { name: 'John Doe', id: '123' };

    // can be called multiple times, it adds something to the context and passes it to the next callback
    await next();
});

app.use(async (ctx, next) => {
    ctx.cookies.set('trackingId', '123');
});

// Hapi.js
import Hapi from '@hapi/hapi';

const server = Hapi.server({
    port: 3000,
    host: 'localhost',
});

server.route({
    method: 'GET',
    path: '/hello',
    handler: async (req, h) => {
        return 'Hello from Hapi!';
    },
});

server.start().then(() => {
    console.log('Hapi server is listening on port 3000');
});
```

## Express.js

Express.js is a middleware driven framework. It means that in the end is all about tunneling the incoming request through a bunch of different functions, which all functions receive the request and all can do something with the request. Each function can stop the request and send back a response, or forward the request to the next middleware in the line. Express is a fast, unopinionated, minimalist web framework for Node.js. We can use it to build a web-server for hosting simple static webpages or very complex backends.

```html
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Document</title>
    </head>
    <body>
        <h1>Hello <%= user %></h1>
        <form method="POST" action="">
            <input name="username" type="text" />
            <button type="submit">Send</button>
        </form>
    </body>
</html>
```

```js
// server.js
const express = require('express');
const bodyParser = require('body-parser');

const app = express(); // creates an instance of express

app.set('view engine', 'ejs'); // configure express engine to use ejs as engine for parsing views/templates
app.set('views', 'views'); // configure the path to the views to be parsed

app.use(bodyParser.urlencoded({ extended: false })); // parses the request then passes it to the next middleware

app.use((req, res, next) => {
    res.setHeader('Content-Type', 'text/html'); // set content type of the response
    next(); // pass/forward request to the next middleware (request handler)
});

app.use((req, res, next) => {
    const username = req.body.username || 'Unknown user'; // request is already parsed by the previous middleware
    res.render('index', {
        // render the view
        user: username, // send the user binded to the <% user %> in the ejs template
    });
});

app.listen(3000);
```

## Basic REST Router

```js
// location.js
const express = require('express');

const router = express.Router(); // middleware

router.post('/add-location', (req, res, next) => {
    // only incoming post requests filtered by this endpoint
    // do something with the req
    res.json({ message: 'Request received' });
});

router.get('/add-location', (req, res, next) => {});

module.exports = router;

// server.js
const locationRouter = require('location');

app.use(locationRouter);
```

## Cross-Origin Resource Sharing (CROSS)

Exchanging resources between two different servers. By default, only requests to same origin (domain) are allowed by the browser.

```js
app.use((req, res, next) => {
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'POST, GET, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
    next();
});
```

## REST API

Representational State Transfer – Application Programming Interface (REST API or RESTful API)

The generic HTTP Request hold the following properties:
• The request line (Method, resourse and protocol
• Request Headers (key/value pairs) holding metadata
• Request body

```js
const request = require('request');

const url = 'https://jsonplaceholder.typicode.com/todos/1';

request({ url: url, json: true }, (error, response) => {
    const data = JSON.parse(response.body);
    console.log(data);
});
```

```js
const http = require('http');
const server = http.createServer((req, res) => {
    res.write('Hello');
    res.end();
});
server.listen(3000);

// Sending Responses
const server = http.createServer((req, res) => {
    res.setHeader('Content-Type', 'text/html');
    res.write('<h1>Hello There</h1>');
    res.end();
});

// Parsing Incoming Data
const server = http.createServer((req, res) => {
    req.on('data', (chunk) => {});
    res.setHeader('Content-Type', 'text/html');
    res.write('<h1>Hello There</h1>');
    res.end();
});
```

```js
const https = require('https');

const url = 'https://jsonplaceholder.typicode.com/todos/1';

const request = https.request(url, (response) => {
    response.on('data', (data) => {
        console.log(data.toString());
    });
});

request.on('error', (error) => {
    console.log('An error', error);
});

request.end();
```

## Asynchronous HTTP request

There are many ways to do an asynchronous http request. For example we can use the “request” module.

## Asynchronous HTTP request without module

We can also use the built in http/https modules to make an asynchronous request.

## Database Interactions

SQL stands for Structured Query Language, and NoSQL stands for Not-Only Structured Query Language.

    1. SQL
    2. NoSQL

SQL → Uses Table → Row entry or Record → Column
NoSQL → Collection → Documents (JSONs) → Fields
CRUD → Create Read Update Delete

Some programs are intended to interface with a database of some sort. There are two types of databases:

1. Use **NoSQL** MongoDB with Node.js
2. Use **SQL** databases with Node.js

With MongoDB we can create REST APIs (CRUD)
Mongoose can help us introduce elegant validations for Mongodb:

1. Writing validations for Mongodb
2. Sanitization for Mongodb

```js
import mysql from 'mysql';

const connection = mysql.createConnection({
    host: 'localhost',
    database: 'node_course_schema',
    user: 'root',
    password: 'root',
});

connection.connect();

const products = [];
connection.query('INSERT INTO products (id, name, price) VALUES ?', [products], (err, results) => {
    // use the ? when working with SQL, never allow raw strings inside sql - SQL INJECTION
    if (err) console.log(err);
    console.log(results);
});

connection.end();
```

```js
import { MongoClient } from 'mongodb';

const execute = async () => {
    // connect to mongodb
    const client = await MongoClient.connect('mongodb://localhost:27017');

    // get a reference to testdb database
    const db = client.db('testdb');

    // get a reference to employeedetails collection
    await db.collection('employeedetails').insertOne({
        name: 'Tom',
    });
    console.log('Done inserting into mongodb');

    // when done interacting with the database call close
    client.close();
};

execute();
```

```js
const mongodb = require('mongodb');
const { MongoClient, ObjectID } = mongodb;

// CRUD create read update delete
const connectionURL = 'mongodb://127.0.0.1:27017';
const databaseName = 'task-manager';

const id = new ObjectID();
console.log(id);

MongoClient.connect(connectionURL, { useNewUrlParser: true }, (error, client) => {
    if (error) {
        return console.log('Unable to connect to database');
    }

    const db = client.db(databaseName);

    db.collection('users').insertOne({
        name: 'John',
        age: 32,
    });

    // Inserting Documents
    db.collection('tasks').insertMany(
        [
            {
                description: 'Clean the house',
                completed: true,
            },
            {
                description: 'Renew inspection',
                completed: false,
            },
            {
                description: 'Pot plants',
                completed: true,
            },
        ],
        (error, result) => {
            if (error) {
                return console.log('Unable to insert tasks');
            }

            console.log(result.ops);
        }
    );

    db.collection('tasks').findOne({ _id: new ObjectID('904234...42342') }, (error, tasks) => {
        console.log(tasks);
    });

    db.collection('tasks')
        .find({ completed: true })
        .toArray((error, tasks) => {
            if (error) {
                console.log(error);
            }

            console.log(tasks);
        });

    // We can also use Promises instead of Callback functions
    db.collection('tasks')
        .updateMany(
            {
                completed: false,
            },
            {
                $set: {
                    completed: true,
                },
            }
        )
        .then((result) => {
            console.log(result.modifiedCount);
        })
        .catch((error) => {
            console.log(error);
        });
});
```

## Websocket

Web-sockets allow us to implement real-time, two-way communication. Web-sockets allow real-time, two-way communication between the front-end and back-end.

1. Create web-sockets
2. Send messages via web-sockets
3. Subscribe to web-socket events

```js
// module for the server side
const io = require('socket.io');

// module for the client side
const io = require('socket.io-event');

socket.on('myEvent', callback);
socket.emit('myEvent', data);

// server-1.js
import express from 'express';
import http from 'http';
import socketIo from 'socket.io';

const app = express();
const server = http.createServer(app);
const io = socketIo(server);

// important event for server
io.on('connection', (socket) => {
    console.log('Connected to:', socket.client.id);

    socket.on('message', (data) => {
        console.log(data);
        // socket.emit('someOtherEvent', { message: 'Hello!' });
    });

    // another important event for the server
    socket.on('disconnect', () => {
        console.log('Disconnected from:', socket.client.id);
    });
});

server.listen(8000, () => {
    console.log('waiting for connections on port 8000');
});

// server-2.js
import { io } from 'socket.io-client';

const createSocketClient = (name, interval) => {
    const socket = io('http://localhost:8000/');

    socket.on('connect', () => {
        console.log(`${name} connected!`);

        setInterval(() => {
            socket.emit('message', `Hello from ${name}`);
        }, interval);
    });

    socket.on('disconnect', () => {
        console.log(`${name} disconnected!`);
    });
};

createSocketClient('Server1', 3000);
createSocketClient('Server2', 5000);
```

## Creating and Publishing an NPM packages

1. First we need to understand the structure of an NPM package.
2. Create an NPM package
3. Publish a package on npm registry

In order to be able to publish an NPM package to the NPM registry:

1. Must have a unique name
2. Define major version, minor version & Patch
3. Describe the packages
4. Set main - an entry point to the application

Steps:

1. Run npm init (set proper info)
2. Write code
3. Create npm account
4. Run npm publish

## Hosting Node.js applications

In order to host a Node.js application we need to address the following things first:

1. Prepare Node.js application for production
2. Host a Node.js application on Heroku

steps:

1. Export/Set environment variables
2. Add deployment scripts under package.json
3. Use heroku-cli (or any other alternatives to Heroku)

## Test Node.js applications

1. Write unit tests with **Mocha** and **Chai**
2. Test server endpoints with **Superset**
3. Create test scripts
4. Run test scripts automatically
5. Ensure and display test coverage

"The tool itself isn't as important as how you use the tool"

- Test Environment/Test-Runner → Command to start tests
- Testing Framework → Generally something that organizes our tests into test suites, organizing the different tests we write in different categories etc.
- Assertion Library → Basic task of an assertion library is to give us a nice syntax to make testable claim of our code, to check for certain code conditions.

The general and preferred structure for testing is to have the tests near the files that we are testing, instead of a completely different file tree. So that we can address the changes quickly. This mainly applies to JavaScript files.

Steps:

1. Run `npm install –save-dev mocha chai`
2. Write test first (Test Driven Development)
3. Write actual code
4. Run `npx mocha "./tests/\*.test.js" –recursive`
5. Run `npm install –save-dev @babel/register`
6. Run `npx mocha "./tests/\*.test.js" --recursive --require @babel/register`
7. Run `npm install --save-dev supertest`
8. Import server or app (from express web-server)
9. Import request from supertest
10. Pass the imported app to request call
11. Tricky point – don’t forget to pass “done” as argument to test callback, otherwise tests will fail (report as passing). Call done when an asynchronous test is finished.
12. Write test scripts under package.json
13. Run test automatically (use watch keyword) to check for test addresses and get instant feedback when changing codes. Generally it is advised to use two different test scripts – first without watch for continuous automated tests, and another using watch for development.
14. `npx mocha "./tests/\*.test.js" --recursive --require @babel/register watch`
15. Install nyc package to display test metrics and test coverage
16. Add nyc script under package.json `npx nyc --reporter=lcov --reporter=text npm run test`

```js
// index.js
import express from 'express';

const app = express();

app.listen(3000, () => {
    console.log('App started listening on port 3000');
});

app.get('/hello', (req, res) => {
    res.send('Hello!');
});

export const getPropertyWithDefault = (propertyName, defaultValue, obj) => {
    // const name = person.name || N/A
    return obj[propertyName] || defaultValue;
};

export default app;

// index.test.js
import request from 'supertest';
import { expect } from 'chai';
import app, { getPropertyWithDefault } from './index';

// In Test Driven Development tests are written before actual code is (index.test.js -> index.js)
// Keep tests as simple as possible - Tests are effective when they are kept simple
// Always expect that a value matches
describe('getPropertyWithDefault - basic functionality', () => {
    it('returns the correct value when the property exists', () => {
        const person = { name: 'John Doe', age: 32, hairColor: 'black' };
        const actual = getPropertyWithDefault('name', 'N/A', person);
        const expected = 'John Doe';

        expect(actual).to.equal(expected);
    });
});

describe('/hello endpoint functionality', () => {
    it('replies with "Hello!" when a GET request is sent', (done) => {
        request(app).get('/hello').expect('Hello!', done);
    });
});
```

## Git

Version Control with Git

1. Untracked Files → `git add`
2. Staged Changes → `git commit`
3. Commits

If files are tracked and we make any change in it then they are considered Unstaged Changes (already Tracked Files).

1. Unstaged Changes → `git add`
2. Staged Changes → `git commit`
3. Commits

SSH & Git

The general approach is to create an ssh, a pair of private and public keys.

Steps:

1. `ls -a -l ~/.ssh`
2. `ssh-keygen -t rsa -b 4096 -C "john.doe@gmail.com"`
3. `eval "$(ssh-agent -s)"`
4. `ssh-add ~/.ssh/id_rsa`
5. `add SSH to Github`
6. `ssh -T git@github.com` (Test github connection)
